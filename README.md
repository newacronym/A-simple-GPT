# A-simple-GPT

A decoder-only GPTModel following the paper "Attention is All You Need"
`https://arxiv.org/abs/1706.03762`

### Dataset
```https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt```
~1M tokens ( character level )

### Model Parameters
~10M trainable parameters

### Hyperparameters used
No. of Embeddings = 384 <br/>
No. of Heads = 6 <br/>
No. of Layers = 6 <br/>


